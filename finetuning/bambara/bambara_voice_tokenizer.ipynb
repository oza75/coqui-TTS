{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "! pip install transformers[torch] datasets tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import normalizers\n",
    "from typing import List\n",
    "import re\n",
    "import tokenizers\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import soundfile as sf\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:35:36.981779Z",
     "start_time": "2024-04-24T00:35:36.930349600Z"
    }
   },
   "id": "d0ee46fa715e90ee",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'source_dataset'],\n    num_rows: 353926\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_ds = load_dataset(\"oza75/bambara-texts\", split=\"train\")\n",
    "bam_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:52:01.299522900Z",
     "start_time": "2024-04-09T00:51:58.471984700Z"
    }
   },
   "id": "d4173c29d286a63",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class VoiceBambaraTextPreprocessor:\n",
    "\n",
    "    def preprocess_batch(self, texts: List[str]) -> List[str]:\n",
    "        return [self.preprocess(text) for text in texts]\n",
    "\n",
    "    def preprocess(self, text: str) -> str:\n",
    "        text = text.lower()\n",
    "        text = self.expand_number(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def expand_number(self, text):\n",
    "        \"\"\"\n",
    "        Normalize Bambara text for TTS by replacing numerical figures with their word equivalents.\n",
    "\n",
    "        Args:\n",
    "        text (str): The text to be normalized.\n",
    "    \n",
    "        Returns:\n",
    "        str: The normalized Bambara text.\n",
    "        \"\"\"\n",
    "\n",
    "        # A regex pattern to match all numbers\n",
    "        number_pattern = re.compile(r'\\b\\d+\\b')\n",
    "\n",
    "        # Function to replace each number with its Bambara text\n",
    "        def replace_number_with_text(match):\n",
    "            number = int(match.group())\n",
    "            return self.number_to_bambara(number)\n",
    "\n",
    "        # Replace each number in the text with its Bambara word equivalent\n",
    "        normalized_text = number_pattern.sub(replace_number_with_text, text)\n",
    "\n",
    "        return normalized_text\n",
    "\n",
    "    def number_to_bambara(self, n):\n",
    "\n",
    "        \"\"\"\n",
    "        Convert a number into its textual representation in Bambara using recursion.\n",
    "        Args:\n",
    "        n (int): The number to be converted.\n",
    "        Returns:\n",
    "        str: The number expressed in Bambara text.\n",
    "        Examples:\n",
    "        >>> number_to_bambara(123)\n",
    "        'kɛmɛ ni mugan ni saba'\n",
    "        Notes:\n",
    "        This function assumes that 'n' is a non-negative integer.\n",
    "        \"\"\"\n",
    "\n",
    "        # Bambara numbering rules\n",
    "        units = [\"\", \"kɛlɛn\", \"fila\", \"saba\", \"naani\", \"duuru\", \"wɔrɔ\", \"wòlonwula\", \"sɛɛgin\", \"kɔnɔntɔn\"]\n",
    "        tens = [\"\", \"tan\", \"mugan\", \"bisaba\", \"binaani\", \"biduuru\", \"biwɔrɔ\", \"biwòlonfila\", \"bisɛɛgin\", \"bikɔnɔntɔn\"]\n",
    "        hundreds = [\"\", \"kɛmɛ\"]\n",
    "        thousands = [\"\", \"waga\"]\n",
    "        millions = [\"\", \"milyɔn\"]\n",
    "\n",
    "        # Handle zero explicitly\n",
    "        if n == 0:\n",
    "            return \"\"  # bambara does not support zero\n",
    "\n",
    "        if n < 10:\n",
    "            return units[n]\n",
    "        elif n < 100:\n",
    "            return tens[n // 10] + (\" ni \" + self.number_to_bambara(n % 10) if n % 10 > 0 else \"\")\n",
    "        elif n < 1000:\n",
    "            return hundreds[1] + (\" \" + self.number_to_bambara(n // 100) if n >= 200 else \"\") + (\" ni \" + self.number_to_bambara(n % 100) if n % 100 > 0 else \"\")\n",
    "        elif n < 1_000_000:\n",
    "            return thousands[1] + \" \" + self.number_to_bambara(n // 1000) + (\n",
    "                \" ni \" + self.number_to_bambara(n % 1000) if n % 1000 > 0 else \"\")\n",
    "        else:\n",
    "            return millions[1] + \" \" + self.number_to_bambara(n // 1_000_000) + (\n",
    "                \" ni \" + self.number_to_bambara(n % 1_000_000) if n % 1_000_000 > 0 else \"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:52:02.922221500Z",
     "start_time": "2024-04-09T00:52:02.912230600Z"
    }
   },
   "id": "4d522c52c87647d1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=2000,\n",
    "    special_tokens=[\"[STOP]\", \"[UNK]\", \"[SPACE]\", \"[START]\", \"[bm]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")\n",
    "\n",
    "text_preprocessor = VoiceBambaraTextPreprocessor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:27:41.286834700Z",
     "start_time": "2024-04-09T10:27:41.280662Z"
    }
   },
   "id": "f026ed92078ecc40",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def batch_iterator(batch_size=1000):\n",
    "    for i in range(0, len(bam_ds), batch_size):\n",
    "        yield text_preprocessor.preprocess_batch(bam_ds[i: i + batch_size][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:27:45.078568200Z",
     "start_time": "2024-04-09T10:27:45.075470700Z"
    }
   },
   "id": "2027bfa5070209f3",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer, length=len(bam_ds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:27:59.113969Z",
     "start_time": "2024-04-09T10:27:47.660547900Z"
    }
   },
   "id": "a730cdbc1e9162c4",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.save(\"./saved/bam_vocab.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:00.654940Z",
     "start_time": "2024-04-09T10:28:00.591076600Z"
    }
   },
   "id": "ec65ae1f96591fa7",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Encoding(num_tokens=10, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=10, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=10, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = tokenizer.encode_batch(text_preprocessor.preprocess_batch(bam_ds['text'][:10]))\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:08.772023100Z",
     "start_time": "2024-04-09T10:28:07.759462800Z"
    }
   },
   "id": "67cc3955ce86b2e0",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['bi',\n ',',\n 's',\n 'ur',\n 'ɔ',\n 'fana',\n 'dun',\n 'nen',\n 'kɔ',\n ',',\n 'n',\n 'bɛ',\n 'na',\n 'an',\n 'ka',\n 'baro',\n 'kɛ',\n '.']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[5].tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:10.958286900Z",
     "start_time": "2024-04-09T10:28:10.876130Z"
    }
   },
   "id": "81d3d747361b7b0e",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8425c2b611e69a52"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['ɔ',\n '̀',\n 'ɔ',\n '̀',\n 'wɔ',\n '́',\n ',',\n 'n',\n 'í',\n 'dɔ',\n '́',\n 'b',\n 'ó',\n 'lo',\n 'k',\n 'ò',\n 'ra',\n ',',\n 'n',\n 'ù',\n 'mu',\n 'kɛ',\n 'b',\n \"'\",\n 'à',\n 'fɔ',\n '́',\n 'k',\n 'ó',\n ',',\n 'dɔ',\n '́',\n 'ka',\n 'n',\n 'à']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = tokenizer.encode(text_preprocessor.preprocess(\"Ɔ̀Ɔ̀ wɔ́, ní dɔ́ bólokòra, nùmukɛ b'à fɔ́ kó, dɔ́ ka nà\"))\n",
    "outputs.tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:16.448429800Z",
     "start_time": "2024-04-09T10:28:16.386015800Z"
    }
   },
   "id": "d00181372d83aa3f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def integrate_vocabs(main_vocab_path, bam_vocab_path, output_dir):\n",
    "    # Load the main vocabulary\n",
    "    with open(main_vocab_path, 'r', encoding='utf-8') as f:\n",
    "        main_vocab = json.load(f)\n",
    "    main_tokens = set(main_vocab['model']['vocab'].keys())\n",
    "    next_id = max(main_vocab['model']['vocab'].values()) + 1\n",
    "\n",
    "    # Load the Bambara vocabulary\n",
    "    with open(bam_vocab_path, 'r', encoding='utf-8') as f:\n",
    "        bam_vocab = json.load(f)\n",
    "    bam_tokens = set(bam_vocab['model']['vocab'].keys())\n",
    "    \n",
    "    # Add tokens from bam_vocab to main_vocab if they don't exist\n",
    "    for token in bam_tokens:\n",
    "        if token not in main_tokens:\n",
    "            main_vocab['model']['vocab'][token] = next_id\n",
    "            next_id += 1\n",
    "    \n",
    "    # Now for the merges\n",
    "    main_merges = set(main_vocab['model']['merges'])\n",
    "    bam_merges = set(bam_vocab['model']['merges'])\n",
    "\n",
    "    # Add merges from bam_vocab to main_vocab if they don't exist\n",
    "    for merge in bam_merges:\n",
    "        if merge not in main_merges:\n",
    "            main_vocab['model']['merges'].append(merge)\n",
    "\n",
    "    # Save the updated vocabulary\n",
    "    output_vocab_path = os.path.join(output_dir, 'combined_vocab.json')\n",
    "    with open(output_vocab_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(main_vocab, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Updated vocabulary saved to {output_vocab_path}\")\n",
    "    return output_vocab_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:29:16.177405200Z",
     "start_time": "2024-04-09T10:29:16.128536900Z"
    }
   },
   "id": "464e0ac06e6bafd9",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated vocabulary saved to ./saved/combined_vocab.json\n"
     ]
    }
   ],
   "source": [
    "# Specify the paths to your main and Bambara vocab files\n",
    "main_vocab_path = './saved/xtts_default_vocab.json'\n",
    "bam_vocab_path = './saved/bam_vocab.json'\n",
    "output_dir = './saved'\n",
    "\n",
    "# Integrate the Bambara vocab into the main vocab and save the updated vocab\n",
    "updated_vocab_path = integrate_vocabs(main_vocab_path, bam_vocab_path, output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:29:19.620043300Z",
     "start_time": "2024-04-09T10:29:19.540517Z"
    }
   },
   "id": "23e164a6bdf63f75",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "combined_tokenizer = Tokenizer.from_file(\"./saved/combined_vocab.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:30:39.166551900Z",
     "start_time": "2024-04-09T10:30:39.130175300Z"
    }
   },
   "id": "2434350effaeabdb",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[5773,\n 41,\n 5760,\n 2839,\n 1127,\n 7738,\n 6047,\n 6888,\n 467,\n 5765,\n 59,\n 2778,\n 691,\n 14,\n 6878,\n 15,\n 1969,\n 43,\n 456,\n 27,\n 941,\n 1270,\n 7312,\n 494,\n 1153,\n 7289,\n 832,\n 512,\n 650,\n 14,\n 165,\n 2351,\n 43,\n 182,\n 571,\n 7496,\n 7798,\n 9]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tokenizer.encode(\"Nin Avrili kalo daminɛ na Farafinna tilebiyanfan jamana dɔw la futɛni barika bonyan fo ka dama tɛmɛ.\").ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:32:52.032969500Z",
     "start_time": "2024-04-09T10:32:51.972958700Z"
    }
   },
   "id": "99bb3daf9aed9256",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 189M/189M [00:16<00:00, 11.5MB/s] \n",
      "Downloading data: 100%|██████████| 159M/159M [00:12<00:00, 12.5MB/s] \n",
      "Downloading data: 100%|██████████| 156M/156M [00:12<00:00, 12.2MB/s] \n",
      "Downloading data: 100%|██████████| 140M/140M [00:12<00:00, 11.2MB/s] \n",
      "Downloading data: 100%|██████████| 167M/167M [00:14<00:00, 11.2MB/s] \n",
      "Downloading data: 100%|██████████| 442M/442M [00:37<00:00, 11.6MB/s] \n",
      "Downloading data: 100%|██████████| 772M/772M [01:04<00:00, 11.9MB/s] \n",
      "Downloading data: 100%|██████████| 464M/464M [00:38<00:00, 12.0MB/s] \n",
      "Downloading data: 100%|██████████| 623M/623M [00:51<00:00, 12.0MB/s] \n",
      "Downloading data: 100%|██████████| 736M/736M [01:00<00:00, 12.1MB/s] \n",
      "Downloading data: 100%|██████████| 742M/742M [01:04<00:00, 11.5MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/8430 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a93bf246e5c4aa08cec295088cf371e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['audio', 'text', 'speaker_id', 'lang'],\n        num_rows: 8430\n    })\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam_multi_ds = load_dataset(\"oza75/bambara-multi-tts\", \"enhanced\")\n",
    "bam_multi_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:35:18.861214900Z",
     "start_time": "2024-04-24T00:28:31.376036700Z"
    }
   },
   "id": "9bfb62fee2008e0f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def select_and_save_audio_samples(dataset, speaker_id, num_samples=10, audio_column='audio'):\n",
    "    \"\"\"\n",
    "    Selects a specified number of random audio samples for a given speaker from a dataset,\n",
    "    and saves them to a designated directory.\n",
    "\n",
    "    Args:\n",
    "    dataset (Dataset): The Hugging Face dataset containing audio data.\n",
    "    audio_column (str): The name of the column in the dataset that contains the audio file paths.\n",
    "    speaker_id (str): The speaker ID to filter the audio samples by.\n",
    "    num_samples (int): The number of random samples to select and save.\n",
    "    \"\"\"\n",
    "    # Filter the dataset for the specified speaker\n",
    "    speaker_data = dataset.filter(lambda ex: [x == speaker_id for x in ex['speaker_id']], batched=True, batch_size=10000)\n",
    "\n",
    "    # Check if there are enough samples for the requested number\n",
    "    if len(speaker_data) < num_samples:\n",
    "        raise ValueError(\"The number of samples requested exceeds the number available for this speaker.\")\n",
    "\n",
    "    # Randomly select samples\n",
    "    selected_samples = random.sample(list(speaker_data), num_samples)\n",
    "\n",
    "    # Create the directory for the speaker if it does not exist\n",
    "    speaker_dir = f'./reference_audios/speaker_{speaker_id}/'\n",
    "    os.makedirs(speaker_dir, exist_ok=True)\n",
    "\n",
    "    # Save the selected audio files\n",
    "    for index, sample in enumerate(selected_samples):\n",
    "        audio_data = sample[audio_column]['array']\n",
    "        sample_rate = sample[audio_column]['sampling_rate']\n",
    "        destination_path = os.path.join(speaker_dir, f'{index}.wav')\n",
    "        # Write the audio file\n",
    "        sf.write(destination_path, audio_data, sample_rate)\n",
    "        print(f\"Saved: {destination_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:39:22.567206Z",
     "start_time": "2024-04-24T00:39:22.557579100Z"
    }
   },
   "id": "46227afef4b0bab3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/8430 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30b5a79e4e0a40bdb5fe309bd1d9f895"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(array([ 31,  35,  38,  39,  41,  43,  45,  46,  47,  49,  51,  53,  54,\n         55,  57,  58,  59,  61,  62,  63,  67,  74,  77,  79,  83,  85,\n         88,  89,  91,  96, 103, 106, 107, 113, 115, 118, 121, 124, 126,\n        127, 133, 134, 136, 138, 140, 142]),\n array([  2,   8,  11,   1,   1,   8,   2,   2, 164,   4, 370,   1,   6,\n          1,   2,   3,   5,   1,   1, 119,   2,  15,   1,   1,   6,   2,\n         11,   4,  78,   1,   1,   3,   2,  42,   2,  17,   9,  60,   1,\n          1,  16,   1,   1,   9,   1,   1]))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(bam_multi_ds.filter(lambda ex: [x == 'es' for x in ex['lang']], batched=True, batch_size=10000)['train']['speaker_id'], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:56:37.467031400Z",
     "start_time": "2024-04-24T00:56:37.403524100Z"
    }
   },
   "id": "e8743ce5fb7588f0",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/8430 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6016d43b590b4a19934db9d6a8449252"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./reference_audios/speaker_47/0.wav\n",
      "Saved: ./reference_audios/speaker_47/1.wav\n",
      "Saved: ./reference_audios/speaker_47/2.wav\n",
      "Saved: ./reference_audios/speaker_47/3.wav\n",
      "Saved: ./reference_audios/speaker_47/4.wav\n",
      "Saved: ./reference_audios/speaker_47/5.wav\n",
      "Saved: ./reference_audios/speaker_47/6.wav\n",
      "Saved: ./reference_audios/speaker_47/7.wav\n",
      "Saved: ./reference_audios/speaker_47/8.wav\n",
      "Saved: ./reference_audios/speaker_47/9.wav\n"
     ]
    }
   ],
   "source": [
    "select_and_save_audio_samples(bam_multi_ds['train'], speaker_id=47)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T00:56:51.081207900Z",
     "start_time": "2024-04-24T00:56:49.799523300Z"
    }
   },
   "id": "dd95bbe20e390637",
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
